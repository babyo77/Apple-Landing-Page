{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z0w17H2TsAJ"
      },
      "source": [
        "**Recipe Search using Model2Vec**\n",
        "\n",
        "This notebook demonstrates how to use the Model2Vec library to search for recipes based on a given query. We will use the [recipe dataset](https://huggingface.co/datasets/Shengtao/recipe).\n",
        "We will be using the `model2vec` in different modes to search for recipes based on a query, using both our own pre-trained models, as well as a domain-specific model we will distill ourselves in this tutorial.\n",
        "\n",
        "Three modes of Model2Vec use are demonstrated:\n",
        "1. **Using a pre-trained output vocab model**: Uses a pre-trained output embedding model. This is a very small model that uses a subword tokenizer.\n",
        "2. **Using a pre-trained glove vocab model**: Uses pre-trained glove vocab model. This is a larger model that uses a word tokenizer.\n",
        "3. **Using a custom vocab model**: Uses a custom domain-specific vocab model that is distilled on a vocab created from the recipe dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WUm4pzOWTsAL",
        "outputId": "2cb3386e-c287-45bf-d001-b7dbc3fb0d0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: model2vec in /usr/local/lib/python3.11/dist-packages (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from model2vec) (3.1.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from model2vec) (13.9.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from model2vec) (75.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->model2vec) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->model2vec) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->model2vec) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->model2vec) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# Install the necessary libraries\n",
        "!pip install numpy datasets scikit-learn transformers model2vec pandas\n",
        "\n",
        "# Import the necessary libraries\n",
        "import regex\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "\n",
        "from model2vec import StaticModel\n",
        "from model2vec.distill import distill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "I-927mKpTsAL",
        "outputId": "923e99f9-681c-41dd-86e2-e7f3052c55cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-890df252ad7a>:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'None' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  dataset.fillna(\"None\", inplace=True)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dataset = pd.read_csv(\"companies.csv\")\n",
        "dataset.fillna(\"None\", inplace=True)\n",
        "dataset.head()\n",
        "recipes = dataset[\"overview\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rLYwIgIdTsAL",
        "outputId": "be908fb6-4894-475c-fa18-4354806b6f4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 name                                           overview  \\\n",
              "0            Wetpaint  Wetpaint is a technology platform company that...   \n",
              "1             Flektor  Flektor is a rich-media mash-up platform that ...   \n",
              "2               There  There.com is an online virtual world where any...   \n",
              "3             MYWEBBO  BRAND NEW ONLINE SOCIAL NETWORKING WEBSITE,FOR...   \n",
              "4  THE Movie Streamer  This company shows free movies online on their...   \n",
              "\n",
              "                   description  \n",
              "0  Technology Platform Company  \n",
              "1                         None  \n",
              "2                         None  \n",
              "3                         None  \n",
              "4                         None  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78a82c07-722a-457b-b28e-a2fdf5531dd3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>overview</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wetpaint</td>\n",
              "      <td>Wetpaint is a technology platform company that...</td>\n",
              "      <td>Technology Platform Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Flektor</td>\n",
              "      <td>Flektor is a rich-media mash-up platform that ...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>There</td>\n",
              "      <td>There.com is an online virtual world where any...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MYWEBBO</td>\n",
              "      <td>BRAND NEW ONLINE SOCIAL NETWORKING WEBSITE,FOR...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>THE Movie Streamer</td>\n",
              "      <td>This company shows free movies online on their...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78a82c07-722a-457b-b28e-a2fdf5531dd3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-78a82c07-722a-457b-b28e-a2fdf5531dd3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-78a82c07-722a-457b-b28e-a2fdf5531dd3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c6933344-6404-45ac-a678-46db3325b1a9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c6933344-6404-45ac-a678-46db3325b1a9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c6933344-6404-45ac-a678-46db3325b1a9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dataset[[\\\"name\\\", \\\"overview\\\", \\\"description\\\"]]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Flektor\",\n          \"THE Movie Streamer\",\n          \"There\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"overview\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Flektor is a rich-media mash-up platform that enables consumers to create, remix and share photos and videos on the internet without the need for advanced video-editing skills or software.\\r\\n\\r\\nFox Interactive Media, a division of News Corporation, announced that it had completed the purchase of Flektor on May 30, 2007.  The estimated puchase price is $15-20 million.\",\n          \"This company shows free movies online on their website which, in fact, is not illegal since they are not the ones hosting the videos.\",\n          \"There.com is an online virtual world where anyone can explore, meet friends and play games. It was founded in 1998 by Will Harvey, a Stanford computer science Ph.D. and game developer, and Jeffrey Ventrella, an expert on artificial life from MIT's Media Lab. The duo raised approximately $37 million - including $20 million from employees, $11 million from angel investors and $6 million from Sutter Hill Ventures. In 2005 the company was spun off under Makena Technologies, and in March 2010 There closed to the public. In May 2011, There announced it would reopen as a 18+ Cloud-based service. As of Nov 2013, There is open.\\r\\n\\r\\nThere.com is a subscription service with a monthly fee of $10.00. Additional in-game accessories can be purchased for separate fees.\\r\\n\\r\\nOther online virtual worlds include [Kaneva](http://www.crunchbase.com/company/kaneva), [Second Life](http://www.crunchbase.com/company/secondlife) and [Cyworld](http://www.crunchbase.com/company/cyworld).\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"None\",\n          \"Technology Platform Company\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Display the first few rows of the dataset for the specified columns\n",
        "dataset[[\"name\", \"overview\", \"description\"]].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPmPN5ghTsAM"
      },
      "source": [
        "First, we will set up a function to handle similarity search that we can use in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8XVcZQJATsAM"
      },
      "outputs": [],
      "source": [
        "# Define a function to find the most similar titles in a dataset to a given query\n",
        "def find_most_similar_items(model: StaticModel, embeddings: np.ndarray, query: str, top_k=5) -> list[tuple[int, float]]:\n",
        "    \"\"\"\n",
        "    Finds the most similar items in a dataset to the given query using the specified model.\n",
        "\n",
        "    :param model: The model used to generate embeddings.\n",
        "    :param embeddings: The embeddings of the dataset.\n",
        "    :param query: The query recipe title.\n",
        "    :param top_k: The number of most similar titles to return.\n",
        "    :return: A list of tuples containing the most similar titles and their cosine similarity scores.\n",
        "    \"\"\"\n",
        "    # Generate embedding for the query\n",
        "    query_embedding = model.encode(query)[None, :]\n",
        "\n",
        "    # Calculate pairwise cosine distances between the query and the precomputed embeddings\n",
        "    distances = pairwise_distances(query_embedding, embeddings, metric='cosine')[0]\n",
        "\n",
        "    # Get the indices of the most similar items (sorted in ascending order because smaller distances are better)\n",
        "    most_similar_indices = np.argsort(distances)\n",
        "\n",
        "    # Convert distances to similarity scores (cosine similarity = 1 - cosine distance)\n",
        "    most_similar_scores = [1 - distances[i] for i in most_similar_indices[:top_k]]\n",
        "\n",
        "    # Return the top-k most similar indices and similarity scores\n",
        "    return list(zip(most_similar_indices[:top_k], most_similar_scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT4RT5CuTsAM"
      },
      "source": [
        "**Using a pre-trained output vocab model**\n",
        "\n",
        "In this part, we will use a pre-trained output vocab model to encode the recipes and search using multiple queries. The output vocab model is very small and fast while still providing good results. Since the model uses a sub-word tokenizer, it is able to handle out-of-vocabulary words and provide good results even for words that are not in the base vocab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TMNrA96CTsAM"
      },
      "outputs": [],
      "source": [
        "# Load the M2V output model from the HuggingFace hub\n",
        "model_name = \"minishlab/M2V_base_output\"\n",
        "model_output = StaticModel.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tqSxRoyETsAN",
        "outputId": "7563271b-1659-4bd1-84c7-71caaff1976a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most similar recipes to 'credit card issuer':\n",
            "Title: `India's leading online portal for loans, credit cards. It provides an easy & comprehensive comparison between interested lenders/issuers to loan/card seekers.`, Similarity Score: 0.5704\n",
            "Title: `The Group's principal activity is providing outsourced payment processing services to merchants. The Group provides payment processing solutions for the real time authorisation and settlement of credit and debit cards, corporate purchasing cards, private label storecards, direct debits, direct credits and cheques. The Group's products provide reporting and management tools that help automate the flow of complex payment processes, such as recurring billing, chargeback workflow and payment reconciliation. Products and services include Bank Card, Direct Debit & Direct Credit, Fraud Prevention and Chargeback Management, e-Wallet solutions, Chip & Pin, Corporate Purchasing and Prepay Solutions. The Group's solutions are suitable for merchants processing payments through any channel including Internet, Interactive Television, Unattended Payment Terminal, Call Centre and IVR.`, Similarity Score: 0.5237\n",
            "Title: `Subuno provides a fraud screening SaaS platform to allow merchants leverage multiple fraud detection solutions in the cloud. Subuno helps merchants automate their transaction screening, speed up manual review, and reduce online credit card fraud.`, Similarity Score: 0.5126\n",
            "Title: `Card USA, Inc. offers payment and incentive cards. The company is based in the United States.\r\n",
            "`, Similarity Score: 0.5071\n",
            "Title: `My Best Interest, Inc. created Rate Surfer, a desktop application for use by consumers and small business for managing credit card accounts. Rate surfer's many features include the ability to\r\n",
            "semi-automatically maintain the users' accounts at the lowest interest rate for which they qualify. `, Similarity Score: 0.4960\n"
          ]
        }
      ],
      "source": [
        "# Find recipes using the output embeddings model\n",
        "top_k = 5\n",
        "\n",
        "# Find the most similar recipes to the given queries\n",
        "query = \"credit card issuer\"\n",
        "embeddings = model_output.encode(recipes)\n",
        "\n",
        "results = find_most_similar_items(model_output, embeddings, query, top_k)\n",
        "print(f\"Most similar recipes to '{query}':\")\n",
        "for idx, score in results:\n",
        "    print(f\"Title: `{recipes[idx]}`, Similarity Score: {score:.4f}\")\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBdpliLLTsAN"
      },
      "source": [
        "As can be seen, we get some good results for the queries. The model is able to find recipes that are similar to the query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqFOqFPITsAN"
      },
      "source": [
        "**Using a pre-trained output vocab model**\n",
        "\n",
        "In this part, we will use a pre-trained glove vocab model to encode the recipes and search using multiple queries. The glove vocab model is a bit larger and slower than the output vocab model but can provide better results. However, as we will see, it suffers from the out-of-vocabulary problem, since the glove vocab is not designed for the cooking recipe domain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4QdXFV7TsAN"
      },
      "outputs": [],
      "source": [
        "# Load the M2V glove model from the HuggingFace hub\n",
        "model_name = \"minishlab/M2V_base_glove\"\n",
        "model_glove = StaticModel.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNjLvt3XTsAN",
        "outputId": "ceba3b0b-43d8-48f5-cc76-98828ca3ea3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most similar recipes to 'cheeseburger':\n",
            "Title: `Double Cheeseburger`, Similarity Score: 0.8744\n",
            "Title: `Cheeseburger Meatloaf`, Similarity Score: 0.8246\n",
            "Title: `Cheeseburger Salad`, Similarity Score: 0.8160\n",
            "Title: `Hearty American Cheeseburger`, Similarity Score: 0.8006\n",
            "Title: `Cheeseburger Chowder`, Similarity Score: 0.7989\n",
            "\n",
            "Most similar recipes to 'fattoush':\n",
            "Title: `Simple Macaroni and Cheese`, Similarity Score: 0.0000\n",
            "Title: `Fresh Tomato and Cucumber Salad with Buttery Garlic Croutons`, Similarity Score: 0.0000\n",
            "Title: `Grilled Cheese, Apple, and Thyme Sandwich`, Similarity Score: 0.0000\n",
            "Title: `Poppin' Turkey Salad`, Similarity Score: 0.0000\n",
            "Title: `Chili - The Heat is On!`, Similarity Score: 0.0000\n"
          ]
        }
      ],
      "source": [
        "# Find recipes using the output embeddings model\n",
        "top_k = 5\n",
        "\n",
        "# Find the most similar recipes to the given queries\n",
        "query = \"cheeseburger\"\n",
        "embeddings = model_glove.encode(recipes)\n",
        "\n",
        "results = find_most_similar_items(model_glove, embeddings, query, top_k)\n",
        "print(f\"Most similar recipes to '{query}':\")\n",
        "for idx, score in results:\n",
        "    print(f\"Title: `{recipes[idx]}`, Similarity Score: {score:.4f}\")\n",
        "\n",
        "print()\n",
        "\n",
        "query = \"fattoush\"\n",
        "results = find_most_similar_items(model_glove, embeddings, query, top_k)\n",
        "print(f\"Most similar recipes to '{query}':\")\n",
        "for idx, score in results:\n",
        "    print(f\"Title: `{recipes[idx]}`, Similarity Score: {score:.4f}\")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV0-GHtOTsAN"
      },
      "source": [
        "As can be seen, we get good results when we search for an in vocab query (`cheeseburger`), but when we search for an out-of-vocab query (`fattoush`), the model is not able to find any relevant recipes. To fix this, we will now distill a custom vocab model on the recipe dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baJxCF7nTsAN"
      },
      "source": [
        "**Using a custom vocab model**\n",
        "\n",
        "In this part, we will distill a custom vocab model on the recipe dataset and use it to encode the recipes and search using multiple queries. This will create a domain-specific model2vec model. First, we will set up a function to create a vocabulary from a list of texts (in our case, a list of recipe titles)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzIQmJj3TsAN"
      },
      "outputs": [],
      "source": [
        "# Set up a regex tokenizer to split texts into words and punctuation\n",
        "my_regex = regex.compile(r\"\\w+|[^\\w\\s]+\")\n",
        "\n",
        "def create_vocab(texts: list[str], tokenizer: Whitespace, size: int = 30_000) -> list[str]:\n",
        "    \"\"\"\n",
        "    Create a vocab from a list of texts.\n",
        "\n",
        "    :param texts: A list of texts.\n",
        "    :param tokenizer: A whitespace tokenizer.\n",
        "    :param size: The size of the vocab.\n",
        "    :return: A vocab sorted by frequency.\n",
        "    \"\"\"\n",
        "    counts = Counter()\n",
        "    for text in texts:\n",
        "        tokens = tokenizer.pre_tokenize_str(text.lower())\n",
        "        tokens = [token for token, _ in tokens]\n",
        "        counts.update(tokens)\n",
        "    vocab = [word for word, _ in counts.most_common(size)]\n",
        "    return vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Imcq75LxTsAN",
        "outputId": "8cbb643a-0f4e-47b4-be60-46e738a05467"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:08<00:00,  1.04s/it]\n"
          ]
        }
      ],
      "source": [
        "# Choose a Sentence Transformer model and a tokenizer\n",
        "model_name = \"BAAI/bge-small-en-v1.5\"\n",
        "tokenizer = Whitespace()\n",
        "\n",
        "# Create a custom vocab from the recipe titles\n",
        "vocab = create_vocab(recipes, tokenizer)\n",
        "\n",
        "# Distill a model2vec model using the Sentence Transformer model and the custom vocab\n",
        "model_custom = distill(model_name=model_name, vocabulary=vocab, pca_dims=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bo0r5zAHTsAO",
        "outputId": "4b16d3b5-3c6e-4d45-a3a0-39abeaa20cf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most similar recipes to 'cheeseburger':\n",
            "Title: `Cheeseburger Salad`, Similarity Score: 0.9528\n",
            "Title: `Cheeseburger Casserole`, Similarity Score: 0.9030\n",
            "Title: `Cheeseburger Chowder`, Similarity Score: 0.8635\n",
            "Title: `Cheeseburger Pie`, Similarity Score: 0.8401\n",
            "Title: `Cheeseburger Meatloaf`, Similarity Score: 0.8184\n",
            "\n",
            "Most similar recipes to 'fattoush':\n",
            "Title: `Fattoush`, Similarity Score: 1.0000\n",
            "Title: `Fatoosh`, Similarity Score: 0.7488\n",
            "Title: `Lebanese Fattoush`, Similarity Score: 0.6344\n",
            "Title: `Arabic Fattoush Salad`, Similarity Score: 0.6108\n",
            "Title: `Fattoush (Lebanese Salad)`, Similarity Score: 0.5669\n"
          ]
        }
      ],
      "source": [
        "# Find recipes using the output embeddings model\n",
        "top_k = 5\n",
        "\n",
        "# Find the most similar recipes to the given queries\n",
        "query = \"cheeseburger\"\n",
        "embeddings = model_custom.encode(recipes)\n",
        "\n",
        "results = find_most_similar_items(model_custom, embeddings, query, top_k)\n",
        "print(f\"Most similar recipes to '{query}':\")\n",
        "for idx, score in results:\n",
        "    print(f\"Title: `{recipes[idx]}`, Similarity Score: {score:.4f}\")\n",
        "\n",
        "print()\n",
        "\n",
        "query = \"fattoush\"\n",
        "results = find_most_similar_items(model_custom, embeddings, query, top_k)\n",
        "print(f\"Most similar recipes to '{query}':\")\n",
        "for idx, score in results:\n",
        "    print(f\"Title: `{recipes[idx]}`, Similarity Score: {score:.4f}\")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXKse-YtTsAO"
      },
      "source": [
        "As can be seen, we now get good results for both queries with our custom vocab model since the domain-specific terms are included in the vocab."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}